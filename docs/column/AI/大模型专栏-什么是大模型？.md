---
id: LLMs-AI-what-is-llms
slug: LLMs-AI-what-is-llms
title: 大模型专栏--什么是大模型？
date: 2024-11-24 19:56:15
authors: yuluo
tags: [AI, LLMs]
keywords: [AI, LLMs]
---

<!-- truncate -->

> 前集概要：最近准备写一些关于 AI 的文章，主要记录自己学习 AI 及其 AI 相关的记录。如果有不对的地方欢迎批评指出！

## 什么是大模型

来自 chatGPT 的回答：

> “大模型”通常指的是在机器学习和深度学习领域，尤其是自然语言处理（NLP）和计算机视觉（CV）中，具有大量参数和复杂结构的模型。这些模型通常需要大量的数据和计算资源进行训练。

大模型（arge language model，LLM）：**指具有大规模参数和复杂计算结构的机器学习模型。**使用基于神经网络的模型，通常运用自然语言处理（Natural Language Processing，NLP）技术来处理和计算其输出。NLP 是人工智能（AI）的一个分支领域，专注于使计算机能够理解、解释和生成文本，从而让 LLM 能够执行文本分析、情绪分析、语言翻译和语音识别等任务。

### 大规模参数

大模型通常包含数亿到数千亿个参数。参数的数量直接影响模型的表达能力，使其能够捕捉到更复杂的模式和特征。

### 复杂计算结构

大模型基于深度学习架构，通常使用以下结构：

- **变换器（Transformers）**：如 BERT、GPT、T5 等，这些模型在处理序列数据（如文本）时表现出色。变换器通过自注意力机制来理解输入数据中不同部分之间的关系。
- **卷积神经网络（CNNs）**：虽然主要用于计算机视觉任务，但也可以在某些文本处理任务中使用。

#### 自注意力机制

变换器的核心在于自注意力机制，它允许模型在处理输入序列时对不同位置的单词进行加权，进而理解上下文关系。编码器和解码器的结合使得变换器能够有效地捕获语义信息。

#### 无监督学习

大模型通常在大规模文本数据上进行无监督预训练，然后通过微调（fine-tuning）来适应特定任务。这种策略使得模型能够从大量数据中学习语言的基本特征和规律。

## 大模型的功能

### 文案写作

大模型如 GPT-3、ChatGPT、Claude 和其他类似工具，确实可以用于创作原始文案。这些模型能够生成各种风格的文本，并且可以通过工具如 AI21 Wordspice 来建议修改以改善语法和表达方式。

### 知识库回答

知识密集型自然语言处理（KI-NLP）确实是指利用 LLM 从数字存档中提取信息以回答具体问题。AI21 Studio playground 能够回答常识性问题，展示了这种技术的应用。

### 文本分类

LLM 可以通过聚类技术对文本进行分类，以识别相似的含义或情绪。这种能力广泛应用于客户情感分析、文本关系识别和文档搜索等场景。

### 代码生成

LLM 在根据自然语言提示生成代码方面表现出色。Amazon Q Developer 允许用户使用 Python、JavaScript、Ruby 等多种编程语言进行编程。它还可以用于创建 SQL 查询、编写 Shell 命令和设计网站等。

### 文本生成

文本生成确实可以用于补全不完整的句子、编写产品文档，甚至创作儿童故事等。这种能力使得大模型在内容创作方面非常灵活和实用。

## 大模型的分类

这里说了大模型，那什么是”小模型“？

### 小模型

#### 小模型的定义

小模型通常指的是参数较少、层数较浅的机器学习模型。由于其设计简单，小模型具有轻量级、高效率和易于部署的优点，特别适合于数据量较小或计算资源有限的场景，例如：

- **移动端应用**：在手机或平板上运行，避免过度消耗电池和计算能力。
- **嵌入式设备**：如智能家居设备、传感器等，这些设备通常计算能力较弱。
- **物联网（IoT）**：在分布式设备中进行实时处理和决策。

#### 小模型与大模型的区别

- **参数和层数**：小模型的参数较少，层数较少，而大模型则具有更多的参数和更深的层次结构。
- **表达能力**：大模型通常具有更强的表达能力和更高的准确度，能够处理更复杂的任务。
- **计算资源**：小模型对计算资源的需求较低，而大模型需要更多的计算资源和时间进行训练和推理。

#### 涌现能力

当模型的训练数据和参数不断增加，达到一定的规模后，模型可能展现出新的能力和特性，这被称为“涌现能力”。具备涌现能力的模型被视为独立意义上的大模型，这是小模型与大模型之间的一个关键区别。

### 模型分类

大模型可以根据不同的**特征和应用场景**进行多种分类：

#### **按模型架构分类**

- **变换器（Transformers）**：如 BERT、GPT、T5 等，广泛应用于自然语言处理（NLP）任务。
- **卷积神经网络（CNNs）**：主要用于图像处理和计算机视觉任务，如 ResNet、EfficientNet 等。
- **递归神经网络（RNNs）**：适合处理序列数据，如 LSTM 和 GRU，虽然近年来逐渐被变换器取代。

#### **按任务类型分类**

- **语言模型**：用于文本生成、补全和理解，例如 GPT 系列和 BERT。
- **图像处理模型**：用于图像分类、目标检测和图像生成，如 EfficientNet 和 GAN（生成对抗网络）。
- **多模态模型**：能够处理多种类型的数据（如文本和图像），例如 CLIP 和 DALL-E。

#### **按训练方式分类**

- **监督学习模型**：通过带标签的数据进行训练，例如图像分类的 CNN 模型。
- **无监督学习模型**：利用未标记的数据进行训练，例如自编码器（Autoencoders）。
- **自监督学习模型**：利用数据本身生成标签进行训练，例如 BERT 使用的掩蔽语言模型技术。

#### **按规模分类**

- **小模型**：参数量适中，适合在资源有限的环境中使用。
- **大模型**：参数量在亿级以上，能够处理复杂任务，但需要大量计算资源。

#### 按领域分类

- **通用模型**：可以用于多种任务，例如 OpenAI 的 GPT-3。
- **专用模型**：针对特定任务或行业优化的模型，例如医疗影像分析模型。

#### 按输入不同

甚至我们还可以根据输入的不同，将其划分为：

- **语言大模型（NLP）**：通常用于处理文本数据和理解自然语言。这类大模型的主要特点是它们在大规模语料库上进行了训练，以学习自然语言的各种语法、语义和语境规则。例如：GPT系列（OpenAI）、Bard（Google）、文心一言（百度）。

- **视觉大模型（CV）**：计算机视觉（Computer Vision，CV）领域中使用的大模型，通常用于图像处理和分析。这类模型通过在大规模图像数据上进行训练，可以实现各种视觉任务，如图像分类、目标检测、图像分割、姿态估计、人脸识别等。

- **多模态大模型**：是指能够处理多种不同类型数据的大模型，例如文本、图像、音频等多模态数据。其结合了NLP和CV的能力，以实现对多模态信息的综合理解和分析，从而能够更全面地理解和处理复杂的数据。

## 大模型当前面临的问题

如果你善于百度，肯定能发现一些当前大模型存在的问题，例如

1. 上下文依赖，不能给出独立于上下文的回答；
2. 对新事物的适应性，对新发生的事务没有感知；
3. 语言理解局限：不能理解训练数据之外的言语；
4. 伦理和社会问题：基于错误的数据集，训练出的违反道德和社区的言论输出
5. 数据安全性：公司内部的知识库使用公司私域数据，没有企业愿意承担数据泄露的风险，将自身的私域数据上传第三方平台进行训练
6. .....

等等，这里我总结为三类：

### 数据安全

最好理解的一个问题：在构建一些公司内部的知识库或者客服助手时，一定不会将公司数据上传到第三方平台进行训练。这也就导致模型回答时的局限性。

### 实时学习

> 这里首先提一个概念：人类的工作记忆（working memory）是**一种记忆容量有限的认知系统，被用以暂时保存资讯**。 工作记忆对于推理以及指导决策和行为有重要影响。

大模型的另一个问题是：临时记忆的缺失，可以理解为大模型在处理信息时的短期存储能力。使大模型在处理连续信息时，保持上下文一致性，增强其理解和反应能力。

当前，对记忆的外部处理手段为将交互对话上下文保存在外部系统，在交互时作为输入，一起传递给大模型。确保模型的上下文语境和暂存区记忆，从而做出更有利的决策和回答。**其一定程度上影响偏见的形成。**

### 偏见

其本质是基于条件反射基础上的快思考。可以认为是实时学习的一种， 也就是快速将某一组神经元的权重打满 ，在学习过程中，通过强化某些神经元之间的连接来提高特定信息的处理能力 ，以避免随机依从性不好的问题。

> 海兔的神经元运作如下：
>
> 1） 刺激 -> 缩鳃 
> 2） 多次刺激 -> 习惯化  没有反应
> 3） 经过了一段时间以后 再刺激 -> 缩鳃 
>
> 偏见 就是3次刺激以后 后面无论怎么刺激 都不再缩鳃了。 对应 告诉你多次以后，你就相信了，不需要大量数据的训练。 
> 只是经过一段时间，就会遗忘 ，然后你又不信了
>
> 来自和某位大佬的对话摘抄

如果模型在学习过程中依赖于自己生成的内容，可能会导致其输出的偏见性（幻觉）。这类似于人类的信仰形成——个人的信念系统在缺乏外部验证时，会基于已有的经验进行自我强化。多次刺激后，反应的习惯化说明了偏见的根深蒂固。类似地，模型在接收到特定输出后，可能会对后续输入产生固定的反应模式，这种模式可能需要新的刺激或信息才能打破。

> **具体表现为：好了伤疤忘了疼。**

### 本质

通过改善**临时记忆和偏见机制**，模型有可能实现更接近人类的思考和学习能力。这意味着模型不仅能快速处理信息，还能灵活适应新的情况，减少错误判断和输出。
