<!doctype html>
<html lang="zh-CN" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">语义模型 | 牧生</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://yuluo-yx.github.io/img/og.png"><meta data-rh="true" name="twitter:image" content="https://yuluo-yx.github.io/img/og.png"><meta data-rh="true" property="og:url" content="https://yuluo-yx.github.io/blog/semantic-model"><meta data-rh="true" property="og:locale" content="zh_CN"><meta data-rh="true" name="docusaurus_locale" content="zh-CN"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="zh-CN"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" name="author" content="牧生"><meta data-rh="true" property="og:title" content="语义模型 | 牧生"><meta data-rh="true" name="description" content="为 Higress Semantic Router Plugin 作准备。"><meta data-rh="true" property="og:description" content="为 Higress Semantic Router Plugin 作准备。"><meta data-rh="true" name="keywords" content="Model,LLM"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2025-11-05T00:21:00.000Z"><meta data-rh="true" property="article:author" content="https://github.com/yuluo-yx"><meta data-rh="true" property="article:tag" content="Model,LLM"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://yuluo-yx.github.io/blog/semantic-model"><link data-rh="true" rel="alternate" href="https://yuluo-yx.github.io/blog/semantic-model" hreflang="zh-CN"><link data-rh="true" rel="alternate" href="https://yuluo-yx.github.io/blog/semantic-model" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://1FVT9MRV7U-dsn.algolia.net" crossorigin="anonymous"><link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-S4SD5NXWXF"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-S4SD5NXWXF",{anonymize_ip:!0})</script>



<link rel="search" type="application/opensearchdescription+xml" title="牧生" href="/opensearch.xml">


<script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?04599de77e7588461f7822ce2f5dbffc";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script>
<link rel="icon" href="/img/logo.png">
<link rel="manifest" href="/manifest.json">
<meta name="theme-color" content="#12affa">

<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="牧生 RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="牧生 Atom Feed">
<link rel="alternate" type="application/json" href="/blog/feed.json" title="牧生 JSON Feed">

<script>!function(){console.log("%c Kz Blog %c https://github.com/kuizuo/blog","color: #fff; margin: 1em 0; padding: 5px 0; background: #12affa;","margin: 1em 0; padding: 5px 0; background: #efefef;");document.firstChild?.nodeType!==Node.COMMENT_NODE&&document.prepend(document.createComment("\nThis Webisite Powered By Yuluo Blog.\nWritten by Docusaurus, Coding with Love.\n--------\nLove what you do and do what you love.\n"))}()</script>
<meta name="description" content="牧生的个人博客">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/misans@4.0.0/lib/Normal/MiSans-Normal.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/misans@4.0.0/lib/Normal/MiSans-Medium.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/misans@4.0.0/lib/Normal/MiSans-Semibold.min.css"><link rel="stylesheet" href="/assets/css/styles.f3c58119.css">
<script src="/assets/js/runtime~main.243807c8.js" defer="defer"></script>
<script src="/assets/js/main.52200ea8.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/logo.png"><link rel="preload" as="image" href="/img/logo-white.png"><div role="region" aria-label="跳到主要内容"><a class="skipToContent_sQ9c" href="#__docusaurus_skipToContent_fallback">跳到主要内容</a></div><nav aria-label="主导航" class="navbar navbar--fixed-top navbarHideable_jvwV"><div class="navbar__inner"><div class="navbar__items"><button aria-label="切换导航栏" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.png" alt="牧生" class="themedComponent_MVeU themedComponent--light_h7vJ"><img src="/img/logo-white.png" alt="牧生" class="themedComponent_MVeU themedComponent--dark_mUEU"></div></a></div><div class="navbar__items navbar__items--right"><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">博客</a><a class="navbar__item navbar__link" href="/friends">友链</a><a class="navbar__item navbar__link" href="/about">关于</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">更多</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/docs/column">专栏</a></li><li><a class="dropdown__link" href="/blog/archive">归档</a></li><li><a class="dropdown__link" href="/docs/journey">Journey</a></li></ul></div><div class="toggle_OSfu colorModeToggle_x44X"><button class="clean-btn toggleButton_XIqj toggleButtonDisabled_aIoK" type="button" disabled="" title="切换浅色/暗黑模式（当前为浅色模式）" aria-label="切换浅色/暗黑模式（当前为浅色模式）" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_hCIx"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_tq4o"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_dCNk"><button type="button" class="DocSearch DocSearch-Button" aria-label="搜索 (Command+K)"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">搜索</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_JGzc"><div class="margin-vert--md container"><div class="row"><aside class="col col--2"><nav class="sidebar_brwN thin-scrollbar" aria-label="最近博文导航" style="opacity:0"><div class="backButton_MCHS"><span></span></div><a class="sidebarItemTitle_r4Q1 margin-bottom--sm" href="/blog">博文</a><div role="group"><h3>2025</h3><ul class="sidebarItemList_QwSx clean-list"><li class="sidebarItem_lnhn"><a aria-current="page" class="sidebarItemLink_yNGZ sidebarItemLinkActive_oSRm" href="/blog/semantic-model">语义模型</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/input">学习双拼输入</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/vllm-sr-understand">VSR 项目解析</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/vllm-sr-mom">Vllm Semantic-router MoM 架构</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/trace-transfer">异构服务链路追踪</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/go-style">go style</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/goroutine-close">优雅关闭 GoRoutine</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/mac-mini">Mac Mini 入手后续</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/golang-context">golang context</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/shenyu-init">Apache Shenyu 本地启动及快速入门</a></li></ul></div></nav></aside><main class="col col--8" itemscope="" itemtype="http://schema.org/Blog"><article class="relative px-4 pt-4 pb-3 lg:px-4" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header style="position:relative;z-index:2"><h1 class="" itemprop="headline">语义模型</h1><div class="inline-flex flex-wrap gap-1.5 text-base margin-bottom--md"><div class="inline-flex items-center gap-1"><span></span><time datetime="2025-11-05T00:21:00.000Z" itemprop="datePublished" class="truncate">2025年11月5日</time></div><div class="inline-flex items-center gap-1"><span></span><div class="truncate inline-flex text-center"><div><a class="tag_d0Lz tagRegular_bmnp tag !border-0 p-0.5 text-text hover:text-link" href="/blog/tags/model">Model</a></div><div>/<a class="tag_d0Lz tagRegular_bmnp tag !border-0 p-0.5 text-text hover:text-link" href="/blog/tags/llm">LLM</a></div></div></div><div class="inline-flex items-center gap-1"><span></span><span class="truncate">阅读需 6 分钟</span></div></div></header><div id="__blog-post-container" class="markdown" itemprop="articleBody" style="position:relative"><p>为 Higress Semantic Router Plugin 作准备。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_vMh4" id="transformers">Transformers<a href="#transformers" class="hash-link" aria-label="Transformers的直接链接" title="Transformers的直接链接">​</a></h2>
<p>Huggingface Transformers 是基于一个开源基于 transformer 模型结构提供的预训练语言库，它支持 Pytorch，Tensorflow2.0，并且支持两个框架的相互转换。</p>
<p>其本质上是一个 Encoder-Decoder 架构。因此中间部分的 Transformer 可以分为两个部分：Encoder 和 Decoder。</p>
<p><img decoding="async" loading="lazy" alt="Transformes" src="/assets/images/ai-23-39c594148db8b2e594018b480ae323aa.png" width="823" height="378" class="img_c29J"></p>
<h3 class="anchor anchorWithHideOnScrollNavbar_vMh4" id="decoder-only--encoder-only">Decoder-Only &amp; Encoder-Only<a href="#decoder-only--encoder-only" class="hash-link" aria-label="Decoder-Only &amp; Encoder-Only的直接链接" title="Decoder-Only &amp; Encoder-Only的直接链接">​</a></h3>
<h4 class="anchor anchorWithHideOnScrollNavbar_vMh4" id="decoder-only-模型">Decoder-Only 模型<a href="#decoder-only-模型" class="hash-link" aria-label="Decoder-Only 模型的直接链接" title="Decoder-Only 模型的直接链接">​</a></h4>
<p>GPT Qwen 等属于 Decoder-Only 模型，是生成式模型。</p>
<h4 class="anchor anchorWithHideOnScrollNavbar_vMh4" id="encoder-only-模型">Encoder-Only 模型<a href="#encoder-only-模型" class="hash-link" aria-label="Encoder-Only 模型的直接链接" title="Encoder-Only 模型的直接链接">​</a></h4>
<p>其输出是一个embedding向量。与 decoder-only 的文本回答不同，encoder-only 模型将其“答案”编码成这种压缩的数值形式。</p>
<p>这个向量是模型输入的压缩表示，因此有时 encoder-only 模型也被称为表征模型（representational models）。</p>
<p>经常与 Decoder-Only 的模型一起使用，组建更强大的 AI 应用（例如 RAG）。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_vMh4" id="bert">Bert<a href="#bert" class="hash-link" aria-label="Bert的直接链接" title="Bert的直接链接">​</a></h2>
<p>Bert 全称为 Bidirectional Encoder Representations from Transformers。是一种基于 Transformers 的双向编码器表示，它只使用了 Transformer 中的 Encoder 部分，用于语言理解的预训练模型。改进了单向编码器的局限性，通过双向上下文提供更强大的语义信息提取能力，广泛应用于多项NLP任务，并在多个基准测试中取得突破性成果。</p>
<p>举个例子理解下双向编码器：</p>
<blockquote>
<p>今天天气很差，我们不得不取消户外运动。</p>
</blockquote>
<p>将句中的某个字或词挖走，句子就变成：<code>今天天气很（ ），我们不得不取消户外运动</code>。分别从单向编码（如 GPT）和双向编码（如 BERT）的角度来考虑“（ ）”中应该填什么词。</p>
<p>单向编码只会使用“今天天气很”这五个字的信息来推断“（ ）”内的字或词，从人类角度考虑，使用概率最大的词应该是：“好”“不错”“差”“糟糕”，而这些词可以被划分为截然不同的两类。</p>
<p>双向编码可以利用下文信息“我们不得不取消户外运动”来帮助模型判断，从人类角度考虑，概率最大的词应该是：“差”“糟糕”。</p>
<p>以此就可以直观地感受到，不考虑模型的复杂度和训练数据量，双向编码与单向编码相比，可以利用更多的上下文信息来辅助当前词的语义判断。在语义理解能力上表现更好。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_vMh4" id="modernbert">ModernBERT<a href="#modernbert" class="hash-link" aria-label="ModernBERT的直接链接" title="ModernBERT的直接链接">​</a></h2>
<p>ModernBERT 是 BERT 的现代化版本，旨在提高下游任务的性能和处理效率。与其前身不同，它支持更长的 Token，更现代的训练方式</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_vMh4" id="gpt">GPT<a href="#gpt" class="hash-link" aria-label="GPT的直接链接" title="GPT的直接链接">​</a></h2>
<p>Generative Pre-trained Transformer（GPT）系列是由 OpenA 提出的非常强大的预训练语言模型，这一系列的模型可以在非常复杂的 NLP 任务中取得非常惊艳的效果，例如文章生成，代码生成，机器翻译，Q&amp;A 等。现在已经被广泛应用。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_vMh4" id="qwen3">Qwen3<a href="#qwen3" class="hash-link" aria-label="Qwen3的直接链接" title="Qwen3的直接链接">​</a></h2>
<p>和 GPT 系列模型类似，都是基于 Transforms Decoder 的生成式 AI 模型，由阿里云发布，在架构上和 GPT 略有不同。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_vMh4" id="模型文件结构">模型文件结构<a href="#模型文件结构" class="hash-link" aria-label="模型文件结构的直接链接" title="模型文件结构的直接链接">​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_vMh4" id="模型保存形式">模型保存形式<a href="#模型保存形式" class="hash-link" aria-label="模型保存形式的直接链接" title="模型保存形式的直接链接">​</a></h3>
<ul>
<li>.safetensors 由 Hugging Face 提出，侧重于安全性和效率，适合于那些希望快速部署且对安全有较高要求的场景，尤其在Hugging Face生态中。</li>
<li>.ckpt 文件是 PyTorch Lightning 框架采用的模型存储格式，它不仅包含了模型参数，还包括优化器状态以及可能的训练元数据信息，使得用户可以无缝地恢复训练或执行推理。</li>
<li>.bin 文件不是标准化的模型保存格式，但在某些情况下可用于存储原始二进制权重数据，加载时需额外处理。</li>
<li>.pth 是PyTorch的标准模型保存格式，方便模型的持久化和复用，支持完整模型结构和参数的保存与恢复。</li>
<li>.onnx（Open Neural Network Exchange）文件是一个开放格式，用于表示机器学习模型。它旨在提供一种标准的方式来表示深度学习模型，使得模型可以在不同的框架和工具之间进行转换和互操作</li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_vMh4" id="文件结构">文件结构<a href="#文件结构" class="hash-link" aria-label="文件结构的直接链接" title="文件结构的直接链接">​</a></h3>
<blockquote>
<p>以 Qwen 0.6B 为例。</p>
</blockquote>
<div class="language-text codeBlockContainer_APcc theme-code-block" style="--prism-background-color:hsl(230, 1%, 98%);--prism-color:hsl(230, 8%, 24%)"><div class="codeBlockContent_m3Ux"><pre class="prism-code language-text codeBlock_qGQc thin-scrollbar" style="background-color:hsl(230, 1%, 98%);color:hsl(230, 8%, 24%)"><code class="codeBlockLines_p187"><span class="token-line" style="color:hsl(230, 8%, 24%)"><span class="token plain">Qwen3-0.6B</span><br></span><span class="token-line" style="color:hsl(230, 8%, 24%)"><span class="token plain">├── config.json							# 控制模型的名称、最终输出的样式、隐藏层宽度和深度、激活函数的类别等</span><br></span><span class="token-line" style="color:hsl(230, 8%, 24%)"><span class="token plain">├── generation_config.json</span><br></span><span class="token-line" style="color:hsl(230, 8%, 24%)"><span class="token plain">├── LICENSE</span><br></span><span class="token-line" style="color:hsl(230, 8%, 24%)"><span class="token plain">├── merges.txt</span><br></span><span class="token-line" style="color:hsl(230, 8%, 24%)"><span class="token plain">├── model.safetensors</span><br></span><span class="token-line" style="color:hsl(230, 8%, 24%)"><span class="token plain">├── README.md</span><br></span><span class="token-line" style="color:hsl(230, 8%, 24%)"><span class="token plain">├── tokenizer_config.json</span><br></span><span class="token-line" style="color:hsl(230, 8%, 24%)"><span class="token plain">├── tokenizer.json					# tokenizer.json 和 tokenizer_config.json 分词的配置文件</span><br></span><span class="token-line" style="color:hsl(230, 8%, 24%)"><span class="token plain">└── vocab.json							# vocab.txt 词典文件</span><br></span></code></pre><div class="buttonGroup_6DOT"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_FhaS" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_phi_"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_FfTR"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithHideOnScrollNavbar_vMh4" id="扩展">扩展<a href="#扩展" class="hash-link" aria-label="扩展的直接链接" title="扩展的直接链接">​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_vMh4" id="激活函数">激活函数<a href="#激活函数" class="hash-link" aria-label="激活函数的直接链接" title="激活函数的直接链接">​</a></h3>
<p>神经网络模拟的是人脑中的神经元结构，激活函数旨在帮助网络学习数据中的复杂模式。在神经元中，输入经过一系列加权求和后作用于另一个函数，这个函数就是这里的激活函数。</p>
<p>通俗来讲，就是将输入和输出的映射升纬，使模型适配更多的非线性情况。激活函数可以分为<strong>线性激活函数</strong>（线性方程控制输入到输出的映射，如 <code>f(x)=x</code> 等）以及<strong>非线性激活函数</strong>（非线性方程控制输入到输出的映射，比如<a href="https://zhida.zhihu.com/search?content_id=169155866&amp;content_type=Article&amp;match_order=1&amp;q=Sigmoid&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NjIxODQzODEsInEiOiJTaWdtb2lkIiwiemhpZGFfc291cmNlIjoiZW50aXR5IiwiY29udGVudF9pZCI6MTY5MTU1ODY2LCJjb250ZW50X3R5cGUiOiJBcnRpY2xlIiwibWF0Y2hfb3JkZXIiOjEsInpkX3Rva2VuIjpudWxsfQ.QD5d-fd3mKsXsOCDrGUylt7MMdcCV2eV1LGOr7eDtlk&amp;zhida_source=entity" target="_blank" rel="noopener noreferrer">Sigmoid</a>、<a href="https://zhida.zhihu.com/search?content_id=169155866&amp;content_type=Article&amp;match_order=1&amp;q=Tanh&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NjIxODQzODEsInEiOiJUYW5oIiwiemhpZGFfc291cmNlIjoiZW50aXR5IiwiY29udGVudF9pZCI6MTY5MTU1ODY2LCJjb250ZW50X3R5cGUiOiJBcnRpY2xlIiwibWF0Y2hfb3JkZXIiOjEsInpkX3Rva2VuIjpudWxsfQ.PO9kZ1pGQRpCTWRFPVLeQ-78yKzhFckdRCaSvGteDVM&amp;zhida_source=entity" target="_blank" rel="noopener noreferrer">Tanh</a>、ReLU、LReLU、PReLU、Swish 等）</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_vMh4" id="tokenizer">Tokenizer<a href="#tokenizer" class="hash-link" aria-label="Tokenizer的直接链接" title="Tokenizer的直接链接">​</a></h3>
<p>Tokenizer分词算法是NLP大模型最基础的组件，基于Tokenizer可以将文本转换成独立的token列表，进而转换成输入的向量成为计算机可以理解的输入形式。</p>
<p>根据不同的切分粒度可以把tokenizer分为:</p>
<ol>
<li>基于词的切分，基于字的切分和基于subword的切分。 基于subword的切分是目前的主流切分方式。</li>
<li>subword的切分包括: BPE(/BBPE), <a href="https://zhida.zhihu.com/search?content_id=232891568&amp;content_type=Article&amp;match_order=1&amp;q=WordPiece&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NjIxODQ5MDIsInEiOiJXb3JkUGllY2UiLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjoyMzI4OTE1NjgsImNvbnRlbnRfdHlwZSI6IkFydGljbGUiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9.UXIQzv9zlpUGqPPcNroaBokJhi08uxqo3v33wL3az14&amp;zhida_source=entity" target="_blank" rel="noopener noreferrer">WordPiece</a> 和 Unigram三种分词模型。其中WordPiece可以认为是一种特殊的BPE。</li>
<li>完整的分词流程包括：文本归一化，预切分，基于分词模型的切分，后处理。</li>
<li>SentencePiece是一个分词工具，内置BEP等多种分词方法，基于Unicode编码并且将空格视为特殊的token。这是当前大模型的主流分词方案。</li>
</ol>
<table><thead><tr><th>分词方法</th><th>典型模型</th></tr></thead><tbody><tr><td>BPE</td><td><a href="https://zhida.zhihu.com/search?content_id=232891568&amp;content_type=Article&amp;match_order=1&amp;q=GPT&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NjIxODQ5MDIsInEiOiJHUFQiLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjoyMzI4OTE1NjgsImNvbnRlbnRfdHlwZSI6IkFydGljbGUiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9.2vquQiMyKIUMP8Dzyj_jnPWo5lSaarXxJUochCxrtuk&amp;zhida_source=entity" target="_blank" rel="noopener noreferrer">GPT</a>, GPT-2, GPT-J, GPT-Neo, <a href="https://zhida.zhihu.com/search?content_id=232891568&amp;content_type=Article&amp;match_order=1&amp;q=RoBERTa&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NjIxODQ5MDIsInEiOiJSb0JFUlRhIiwiemhpZGFfc291cmNlIjoiZW50aXR5IiwiY29udGVudF9pZCI6MjMyODkxNTY4LCJjb250ZW50X3R5cGUiOiJBcnRpY2xlIiwibWF0Y2hfb3JkZXIiOjEsInpkX3Rva2VuIjpudWxsfQ.ZektXrcR8blvvv34YbZtYVtHgwWUdbzmK16S8RDfB3o&amp;zhida_source=entity" target="_blank" rel="noopener noreferrer">RoBERTa</a>, <a href="https://zhida.zhihu.com/search?content_id=232891568&amp;content_type=Article&amp;match_order=1&amp;q=BART&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NjIxODQ5MDIsInEiOiJCQVJUIiwiemhpZGFfc291cmNlIjoiZW50aXR5IiwiY29udGVudF9pZCI6MjMyODkxNTY4LCJjb250ZW50X3R5cGUiOiJBcnRpY2xlIiwibWF0Y2hfb3JkZXIiOjEsInpkX3Rva2VuIjpudWxsfQ.qycfCtAgps3rDUzxfkttgQ8xnTwZaucuDOvkGtOx5U0&amp;zhida_source=entity" target="_blank" rel="noopener noreferrer">BART</a>, <a href="https://zhida.zhihu.com/search?content_id=232891568&amp;content_type=Article&amp;match_order=1&amp;q=LLaMA&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NjIxODQ5MDIsInEiOiJMTGFNQSIsInpoaWRhX3NvdXJjZSI6ImVudGl0eSIsImNvbnRlbnRfaWQiOjIzMjg5MTU2OCwiY29udGVudF90eXBlIjoiQXJ0aWNsZSIsIm1hdGNoX29yZGVyIjoxLCJ6ZF90b2tlbiI6bnVsbH0.pj8R6K0qJEnn5cjbDQ4ExHfH5IHtNgnIr5udncucEWM&amp;zhida_source=entity" target="_blank" rel="noopener noreferrer">LLaMA</a>, ChatGLM-6B, <a href="https://zhida.zhihu.com/search?content_id=232891568&amp;content_type=Article&amp;match_order=1&amp;q=Baichuan&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NjIxODQ5MDIsInEiOiJCYWljaHVhbiIsInpoaWRhX3NvdXJjZSI6ImVudGl0eSIsImNvbnRlbnRfaWQiOjIzMjg5MTU2OCwiY29udGVudF90eXBlIjoiQXJ0aWNsZSIsIm1hdGNoX29yZGVyIjoxLCJ6ZF90b2tlbiI6bnVsbH0.ERUHdiUdB_BlembKDtdrSKxS8qWnjK_lWwC6PoiNzjM&amp;zhida_source=entity" target="_blank" rel="noopener noreferrer">Baichuan</a></td></tr><tr><td>WordPiece</td><td>BERT, <a href="https://zhida.zhihu.com/search?content_id=232891568&amp;content_type=Article&amp;match_order=1&amp;q=DistilBERT&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NjIxODQ5MDIsInEiOiJEaXN0aWxCRVJUIiwiemhpZGFfc291cmNlIjoiZW50aXR5IiwiY29udGVudF9pZCI6MjMyODkxNTY4LCJjb250ZW50X3R5cGUiOiJBcnRpY2xlIiwibWF0Y2hfb3JkZXIiOjEsInpkX3Rva2VuIjpudWxsfQ.2RM9mvukGuHbul1PBTu01q5HvPoME9B0ES1ft9CItgo&amp;zhida_source=entity" target="_blank" rel="noopener noreferrer">DistilBERT</a>，<a href="https://zhida.zhihu.com/search?content_id=232891568&amp;content_type=Article&amp;match_order=1&amp;q=MobileBERT&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NjIxODQ5MDIsInEiOiJNb2JpbGVCRVJUIiwiemhpZGFfc291cmNlIjoiZW50aXR5IiwiY29udGVudF9pZCI6MjMyODkxNTY4LCJjb250ZW50X3R5cGUiOiJBcnRpY2xlIiwibWF0Y2hfb3JkZXIiOjEsInpkX3Rva2VuIjpudWxsfQ.OJmwoGXJ-Z2S4h7xrJc5AJFgG1oB6I7JOX5UuTNZfVM&amp;zhida_source=entity" target="_blank" rel="noopener noreferrer">MobileBERT</a></td></tr><tr><td>Unigram</td><td><a href="https://zhida.zhihu.com/search?content_id=232891568&amp;content_type=Article&amp;match_order=1&amp;q=AlBERT&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NjIxODQ5MDIsInEiOiJBbEJFUlQiLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjoyMzI4OTE1NjgsImNvbnRlbnRfdHlwZSI6IkFydGljbGUiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9.hAcxm-yKN_GbuT7PdGHTrrLI2AO3W_W3RJ0abr_4c6o&amp;zhida_source=entity" target="_blank" rel="noopener noreferrer">AlBERT</a>, <a href="https://zhida.zhihu.com/search?content_id=232891568&amp;content_type=Article&amp;match_order=1&amp;q=T5&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NjIxODQ5MDIsInEiOiJUNSIsInpoaWRhX3NvdXJjZSI6ImVudGl0eSIsImNvbnRlbnRfaWQiOjIzMjg5MTU2OCwiY29udGVudF90eXBlIjoiQXJ0aWNsZSIsIm1hdGNoX29yZGVyIjoxLCJ6ZF90b2tlbiI6bnVsbH0.FI844AWqW9iy7Iq-Nmy0Cf8WEaHjZrTi-uAJArPpONQ&amp;zhida_source=entity" target="_blank" rel="noopener noreferrer">T5</a>, <a href="https://zhida.zhihu.com/search?content_id=232891568&amp;content_type=Article&amp;match_order=1&amp;q=mBART&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NjIxODQ5MDIsInEiOiJtQkFSVCIsInpoaWRhX3NvdXJjZSI6ImVudGl0eSIsImNvbnRlbnRfaWQiOjIzMjg5MTU2OCwiY29udGVudF90eXBlIjoiQXJ0aWNsZSIsIm1hdGNoX29yZGVyIjoxLCJ6ZF90b2tlbiI6bnVsbH0.025oeImLIZqtKFDfyL32sbO3M4ComzN4mJI7i6nWhrk&amp;zhida_source=entity" target="_blank" rel="noopener noreferrer">mBART</a>, XLNet</td></tr></tbody></table>
<h3 class="anchor anchorWithHideOnScrollNavbar_vMh4" id="lora-微调">LoRA 微调<a href="#lora-微调" class="hash-link" aria-label="LoRA 微调的直接链接" title="LoRA 微调的直接链接">​</a></h3>
<p>LoRA：Low-Rank Adaptation of Large Language Models（低阶自适应参数高效微调 ）。</p>
<p>基本原理是冻结预训练好的模型权重参数，在冻结原模型参数的情况下，通过往模型中加入额外的网络层，并只训练这些新增的网络层参数。由于这些新增参数数量较少，这样不仅 finetune 的成本显著下降，还能获得和全模型微调类似的效果。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_vMh4" id="参考">参考<a href="#参考" class="hash-link" aria-label="参考的直接链接" title="参考的直接链接">​</a></h2>
<ol>
<li><a href="https://zhuanlan.zhihu.com/p/535100411" target="_blank" rel="noopener noreferrer">https://zhuanlan.zhihu.com/p/535100411</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/1911115248053755995" target="_blank" rel="noopener noreferrer">https://zhuanlan.zhihu.com/p/1911115248053755995</a></li>
<li><a href="https://yuluo-yx.github.io/blog/deep-learn-init/#%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E5%BC%95%E5%85%A5" target="_blank" rel="noopener noreferrer">https://yuluo-yx.github.io/blog/deep-learn-init/#%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E5%BC%95%E5%85%A5</a></li>
<li><a href="https://yuluo-yx.github.io/docs/LLMs-AI-llms-what-token/#%E5%88%86%E8%AF%8D%E5%99%A8%E5%8E%9F%E7%90%86" target="_blank" rel="noopener noreferrer">https://yuluo-yx.github.io/docs/LLMs-AI-llms-what-token/#%E5%88%86%E8%AF%8D%E5%99%A8%E5%8E%9F%E7%90%86</a></li>
</ol></div><footer class="row docusaurus-mt-lg blogPostFooterDetailsFull_Wr5y"></footer></article><div class="margin-bottom--md"><nav class="pagination-nav docusaurus-mt-lg" aria-label="博文分页导航"><a class="pagination-nav__link border-2 border-link hover:bg-[#a1d8f71b] pagination-nav__link--next" href="/blog/input"><div class="pagination-nav__sublabel">较旧一篇</div><div class="pagination-nav__label">学习双拼输入</div></a></nav></div><div>Loading Comments...</div><button aria-label="回到顶部" class="clean-btn theme-back-to-top-button backToTopButton_tR6u" type="button"></button></main><div class="col col--2 px-0.5"><div class="tableOfContents_jeP5 thin-scrollbar" style="opacity:0.0001;transform:translateX(100px)"><ul class="table-of-contents pl-0"><li><a href="#transformers" class="table-of-contents__link toc-highlight">Transformers</a><ul><li><a href="#decoder-only--encoder-only" class="table-of-contents__link toc-highlight">Decoder-Only &amp; Encoder-Only</a><ul><li><a href="#decoder-only-模型" class="table-of-contents__link toc-highlight">Decoder-Only 模型</a></li><li><a href="#encoder-only-模型" class="table-of-contents__link toc-highlight">Encoder-Only 模型</a></li></ul></li></ul></li><li><a href="#bert" class="table-of-contents__link toc-highlight">Bert</a></li><li><a href="#modernbert" class="table-of-contents__link toc-highlight">ModernBERT</a></li><li><a href="#gpt" class="table-of-contents__link toc-highlight">GPT</a></li><li><a href="#qwen3" class="table-of-contents__link toc-highlight">Qwen3</a></li><li><a href="#模型文件结构" class="table-of-contents__link toc-highlight">模型文件结构</a><ul><li><a href="#模型保存形式" class="table-of-contents__link toc-highlight">模型保存形式</a></li><li><a href="#文件结构" class="table-of-contents__link toc-highlight">文件结构</a></li></ul></li><li><a href="#扩展" class="table-of-contents__link toc-highlight">扩展</a><ul><li><a href="#激活函数" class="table-of-contents__link toc-highlight">激活函数</a></li><li><a href="#tokenizer" class="table-of-contents__link toc-highlight">Tokenizer</a></li><li><a href="#lora-微调" class="table-of-contents__link toc-highlight">LoRA 微调</a></li></ul></li><li><a href="#参考" class="table-of-contents__link toc-highlight">参考</a></li></ul><hr class="hr_UhE0"><span class="percent_H6RK">0%<!-- --> </span></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">学习</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">博客</a></li><li class="footer__item"><a class="footer__link-item" href="/blog/archive">归档</a></li></ul></div><div class="col footer__col"><div class="footer__title">有用的东西</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/yuluo-yx/use" target="_blank" rel="noopener noreferrer" class="footer__link-item">use<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_INRw"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/deigmata-paideias/deigmata-paideias" target="_blank" rel="noopener noreferrer" class="footer__link-item">deigmata_paideias<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_INRw"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">更多</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" position="right" href="/friends">友链</a></li><li class="footer__item">
                <a href="https://docusaurus.io" target="_blank" rel="noreferrer noopener">
                  <img src="/img/buildwith.png" alt="build with docusaurus" width="120" height="50">
                </a>
                </li></ul></div><div class="col footer__col"><div class="footer__title">社交媒体</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/about">关于我</a></li><li class="footer__item"><a href="https://github.com/yuluo-yx" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_INRw"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/yuluo_yx" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_INRw"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://blog.csdn.net/qq_52397471" target="_blank" rel="noopener noreferrer" class="footer__link-item">CSDN<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_INRw"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">
        <p style="margin-bottom: 0;"><a href="http://beian.miit.gov.cn/">Everything Wins 🎉</a></p>
        <p style="display: inline-flex; align-items: center;"><a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=undefined">----------------------------------------------</a></p>
        <p>Copyright © 2020 - 2025 牧生. | Built with Docusaurus.</p>
        </div></div></div></footer></div>
</body>
</html>